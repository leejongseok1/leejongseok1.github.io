---
published: true
title: "[DA] A/B 테스트"

categories: DA
tag: [DA, A/B테스트]

toc: true
toc_sticky: true

sidebar:
    nav: "docs"
    nav: "counts"

date: 2024-01-20
---
A/B 테스트란 무엇일까?

<br>

# 🆎 A/B 테스트

A/B 테스트(분할-실행 테스트)란, 마케팅과 웹 분석에서 사용하는 방법으로 대조실험이라고 할 수 있다.

웹페이지, 이메일, 앱 인터페이스 등의 두 가지 버전을 비교하여 사전 정의된 목표 또는 지표 측면에서 어느 버전이 더 나은 성능을 보이는지 결정하는 데 사용된다.

목표는 클릭률 증가, 전환율 향상, 사용자 참여 강화 등 무엇이든 될 수 있다.

<br>

이해를 돕기 위해 상황을 하나 예로 들어보자면,

전자 기기를 판매하는 온라인 상점이 있다고 가정해보자.

"장바구니에 추가" 버튼은 전환율에 영향을 미칠 수 있는 중요한 요소이다.

이 버튼의 두 가지 변형을 테스트하여 어떤 것이 장바구니에 제품을 추가하는 방문자의 비율이 더 높은지 확인하려고 한다.



🅰️ **A 버튼 (원본 버전)** : 버튼은 녹색으로 상품설명 하단에 위치, "장바구니 담기" 텍스트 포함

🅱️ **B 버튼 (변형 버전)** : 제품 설명 위에 빨간색 "장바구니에 추가"버튼이 있고, "지금 구매"라는 텍스트 포함

<br>

📈 **A/B 테스트 결과**

전환율 | '장바구니에 추가' 버튼을 클릭하고 구매를 성공적으로 완료한 방문자 수를 기준으로 계산

|-|클릭률|전환율|사용자당 장바구니에 추가된 제품 수|
|--|--|--|--|
|A|25%|5%|0.6|
|B|28%|6.5%|0.8|

B가 **클릭률 3%**, **전환율 1.5%** 더 나은 성능을 보였다. **사용자 1인당 장바구니에 담긴 평균 상품 수** 또한 **0.2개가 증가**했다.

✅ **결정**

통계적으로 유의미한 결과를 바탕으로 버전 B의 변경 사항을 웹 사이트에 구현하기로 결정했다. A/B 테스트 중에 관찰된 개선 사항을 활용하기 위해 "장바구니에 추가" 버튼이 "지금 구매" 텍스트가 포함된 빨간색 버튼으로 업데이트되었다.

<br>
<br>

**AB 테스트**는 크게 다음과 같은 3단계를 따른다.
1. 💡 **가설 수립**
2. 🔬 **실험 진행**
3. 📊 **결과 분석**

<br>
<br>

## 💡 가설 수립

가설을 세우는 것은 테스트의 시작이다.

A/B 테스트는 가설을 세우고 -> 실험하고 -> 결과를 얻고 -> 결과에서 비롯된 인사이트를 바탕으로 새 가설을 세우고... 이런 연속적인 과정으로 진행되는 AB 테스트의 특성상 한 사이클을 시작하는 가설 세우기 단계에서 순항하느냐, 먼 길을 돌아가느냐가 결정된다.

AB 테스트의 가설은 핵심적인 아이디어와 함께 어떠한 요소를 어떤 방식으로 바꿔서 어떤 지표를 바꿀 것인지 특정해야 한다.

**"원본 A를 대안 B로 바꾸면 지표 X가 Y하게 변할 것이다."**

유저 행동에 영향을 미치는 요소라면 무엇이든지 A/B 테스트 대상이 될 수 있다.

여러가지 가설이 리스트에 있다면 예상되는 효과의 크기와 실행 난이도에 따라서 우선순위를 매기면 된다. 효과가 크고, 실행하기 쉬운 가설부터 실험한다.

<br>
<br>

## 🔬 실험 진행

가설이 수립되면 실험 진행을 준비한다. 실험 진행 단계도 3가지 요소로 나눠볼 수 있다.

1. **분기**
2. **구현**
3. **지표 추적**

<br>

먼저 **분기 단위를 정해야 한다**. 분기는 수립된 가설에 따라 각각 원본 A와 대안 B를 보여줄 트래픽을 분리하는 작업이다. A와 B를 나누는 기준을 말한다.

A/B 테스트를 하기 위해 트래픽을 분기할 때 고려해야 하는 가장 중요한 사항은 나누는 트래픽이 해당 실험에 대해 얼마나 순수한지이다. 

A/B 테스트에 동원된 트래픽이 계획대로 분기됐다면 각각 원본과 대안을 적용해주면 된다. 특별한 규칙이 있는 것은 아니고 버그가 없도록 꼼꼼하게 만들면 된다. 

A/B 테스트 중 대안의 전환율이 큰 폭으로 하락한 사례가 있고, 알고 보니 특정 브라우저에 대안을 적용하면 기능이 작동하지 않는 문제가 있었다고 한다. 이처럼 가설과 무관한 데이터를 받지 않도록 주의해서 대안을 구현하면 된다.

마지막으로 보고자 하는 지표를 추적할 수 있도록 준비가 필요하다. 직접 개발한 경우라면 지표를 DB에서 볼 것인지, 그렇다면 어떤 쿼리를 사용해서 확인할 것인지, 외부 추적 툴을 사용할 것인지, 그렇다면 지표를 추적하기 위한 이벤트는 잘 심겨 있는지 확인해야 한다. AB 테스트 툴을 사용한다면 해당 툴에 맞는 지표 추적 방식을 따르는 게 좋다.

<br>
<br>

## 📊 결과 분석

이제 실험에서 도출된 데이터를 보고 결론을 도출해야 한다.

실험 과정에서 무언가 잘못되었을 수도 있고, 우연의 일치가 일어났을 수도 있기 때문에 실제로 이 결과가 정말로 의미 있는지 알기 위해서는 3단계 확인을 해야한다.

### 불변 지표 (Invariant Metric)

불편 지표란 실험 과정에서 변하면 안되는 변수이다.

실험 과정에서 문제점이 없었는지 재점검을 해보기 위해서 불변 지표가 변하지 않았는지 체크한다.

### 통계적 유의성 (Statistical significance)

어떤 실험 결과를 두고 '통계적으로 유의미하다'고 하는 것은 단순히 우연이라고 보기 어렵다는 뜻이다. 실험에서는 언제나 우연의 가능성이 있기 때문에, 통계적으로 유의미한 결과인지 확인하는 것은 아주 중요하다.

통계적으로 유의미하다는 말은 동시에 이 실험을 다시 한번 해도 똑같은 결과가 나온다는 말이기도 하다. A/B 테스트를 통해서 가설을 입증하고 이를 서비스 전체에 적용하고 싶은 것이기 때문에, 이 결과를 반복해서 나타날 수 있는지 여부를 점검해야 한다.

Hypotehsis testing을 통해서 변화가 '우연히 일어났을 확률'을 구할 수 있는데, 일반적으로 이 확률이 5% 이하이면 통계적으로 유의미한 것으로 본다.

### 현실적 유의성 (Practical significance)

통계적으로 유의미한 결과가 나왔다고 하더라도 바로 그 가설을 적용해서는 안된다. 이 실험 결과를 전체적으로 적용하기 위해서는 시간과 돈이 들기 때문이다. 따라서 현실적으로 유의미하다는 말은 **비용과 시간을 고려했을 때도 충분히 실행할 가치가 있는 가설**이라는 뜻이다. 따라서 이는 상황을 고려해서 직접 결정해야 한다.

<br>
<br>

----

실험 결과가 이 3가지 점검을 모두 통과했다면 가설을 전체 서비스에 적용할 수 있다.

왜 그런 결과가 나왔는지에 대한 이유를 더 파고 들어가야 하고, A/B 테스트는 유저 행동이 변화한 이유는 알려주지 않기 때문이다. 




----

> 참고 :
> https://brunch.co.kr/@bumgeunsong/17
> https://yozm.wishket.com/magazine/detail/585/

